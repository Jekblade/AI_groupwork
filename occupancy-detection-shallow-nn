
#!/usr/bin/env python3
"""
Shallow Neural Network - Occupancy Detection
Using preprocessed sensor data from FinalData.csv
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import (accuracy_score, precision_score, recall_score, 
                             f1_score, confusion_matrix, classification_report,
                             roc_auc_score, balanced_accuracy_score)
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("SHALLOW NEURAL NETWORK - OCCUPANCY DETECTION")
print("="*80)

# Load data
print("\n1. Loading data...")
data = pd.read_csv('FinalData.csv', sep=';')

# Convert datetime
data['datetime'] = pd.to_datetime(data['datetime'], format='%d/%m/%Y %H:%M')

# Rename columns for consistency
data.columns = ['datetime', 'CO2', 'light', 'humidity', 'temp_indoor', 
                'temp_outdoor', 'presence']

print(f"   Total samples: {len(data)}")
print(f"   Date range: {data['datetime'].min()} to {data['datetime'].max()}")

# Add time features
print("\n2. Engineering time-based features...")
data['hour'] = data['datetime'].dt.hour
data['day_of_week'] = data['datetime'].dt.dayofweek
data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)

print("   Added: hour, day_of_week, is_weekend")

# Train/validation split (temporal)
print("\n3. Creating train/validation split...")
split_idx = int(len(data) * 0.9)
train_data = data.iloc[:split_idx].copy()
val_data = data.iloc[split_idx:].copy()

print(f"   Training samples: {len(train_data)} (90%)")
print(f"   Validation samples: {len(val_data)} (10%)")

# Features and target
features = ['CO2', 'light', 'temp_indoor', 'temp_outdoor', 'humidity', 'hour', 'is_weekend']
target = 'presence'

print(f"\n4. Feature selection...")
print(f"   Features: {features}")
print(f"   Target: {target}")

# Extract X and y
X_train = train_data[features].values
y_train = train_data[target].values
X_val = val_data[features].values
y_val = val_data[target].values

# Class distribution
print("\n5. Analyzing class distribution...")
train_counts = pd.Series(y_train).value_counts()
val_counts = pd.Series(y_val).value_counts()

print(f"   Training set:")
print(f"     Unoccupied (0): {train_counts[0]} ({train_counts[0]/len(y_train)*100:.1f}%)")
print(f"     Occupied (1): {train_counts[1]} ({train_counts[1]/len(y_train)*100:.1f}%)")
print(f"\n   Validation set:")
print(f"     Unoccupied (0): {val_counts[0]} ({val_counts[0]/len(y_val)*100:.1f}%)")
print(f"     Occupied (1): {val_counts[1]} ({val_counts[1]/len(y_val)*100:.1f}%)")

# Handle class imbalance
print("\n6. Computing class weights...")
classes = np.unique(y_train)
class_weights_array = compute_class_weight('balanced', classes=classes, y=y_train)
class_weight_dict = {classes[i]: class_weights_array[i] for i in range(len(classes))}
sample_weights = np.array([class_weight_dict[y] for y in y_train])

print(f"   Class weights: {class_weight_dict}")

# Standardize features
print("\n7. Standardizing features...")
scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_val_scaled = scaler.transform(X_val)
print("   Features normalized to mean=0, std=1")

# Build model
print("\n8. Building shallow neural network...")
print("   Architecture:")
print(f"     Input layer: {len(features)} features")
print("     Hidden layer: 50 neurons (ReLU)")
print("     Output layer: 2 classes (softmax)")

model = MLPClassifier(
    hidden_layer_sizes=(50,),
    activation='relu',
    solver='adam',
    alpha=0.01,
    learning_rate='adaptive',
    learning_rate_init=0.01,
    max_iter=300,
    batch_size=32,
    early_stopping=True,
    validation_fraction=0.1,
    n_iter_no_change=20,
    random_state=42,
    verbose=False
)

# Train model
print("\n9. Training model...")
model.fit(X_train_scaled, y_train, sample_weight=sample_weights)
print(f"   Training complete")
print(f"   Iterations: {model.n_iter_}")
print(f"   Final loss: {model.loss_:.6f}")

# Make predictions
print("\n10. Generating predictions...")
y_train_pred = model.predict(X_train_scaled)
y_train_proba = model.predict_proba(X_train_scaled)[:, 1]
y_val_pred = model.predict(X_val_scaled)
y_val_proba = model.predict_proba(X_val_scaled)[:, 1]

# Evaluate performance
print("\n" + "="*80)
print("RESULTS")
print("="*80)

train_acc = accuracy_score(y_train, y_train_pred)
train_bal_acc = balanced_accuracy_score(y_train, y_train_pred)
train_f1 = f1_score(y_train, y_train_pred)

val_acc = accuracy_score(y_val, y_val_pred)
val_bal_acc = balanced_accuracy_score(y_val, y_val_pred)
val_prec = precision_score(y_val, y_val_pred)
val_rec = recall_score(y_val, y_val_pred)
val_f1 = f1_score(y_val, y_val_pred)
val_auc = roc_auc_score(y_val, y_val_proba)

print("\nTRAINING SET PERFORMANCE:")
print(f"   Accuracy:          {train_acc:.4f} ({train_acc*100:.1f}%)")
print(f"   Balanced Accuracy: {train_bal_acc:.4f} ({train_bal_acc*100:.1f}%)")
print(f"   F1-Score:          {train_f1:.4f}")

print("\nVALIDATION SET PERFORMANCE:")
print(f"   Accuracy:          {val_acc:.4f} ({val_acc*100:.1f}%)")
print(f"   Balanced Accuracy: {val_bal_acc:.4f} ({val_bal_acc*100:.1f}%)")
print(f"   Precision:         {val_prec:.4f}")
print(f"   Recall:            {val_rec:.4f}")
print(f"   F1-Score:          {val_f1:.4f}")
print(f"   ROC-AUC:           {val_auc:.4f}")

# Confusion matrix
cm = confusion_matrix(y_val, y_val_pred)
tn, fp, fn, tp = cm.ravel()

print("\nCONFUSION MATRIX (Validation):")
print(f"                 Predicted")
print(f"                 Unocc  Occ")
print(f"   Actual Unocc   {cm[0,0]:3d}   {cm[0,1]:3d}")
print(f"   Actual Occ     {cm[1,0]:3d}   {cm[1,1]:3d}")

specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0

print(f"\n   Specificity: {specificity:.4f} ({specificity*100:.1f}%)")
print(f"   Sensitivity: {sensitivity:.4f} ({sensitivity*100:.1f}%)")

# Classification report
print("\nDETAILED CLASSIFICATION REPORT:")
print(classification_report(y_val, y_val_pred, 
                           target_names=['Unoccupied', 'Occupied'],
                           digits=4))

# Create visualizations
print("\n11. Creating visualizations...")

fig, axes = plt.subplots(2, 2, figsize=(14, 12))
fig.suptitle('Shallow Neural Network - Validation Results', fontsize=16, fontweight='bold')

# Confusion Matrix
ax1 = axes[0, 0]
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=ax1,
            xticklabels=['Unoccupied', 'Occupied'],
            yticklabels=['Unoccupied', 'Occupied'],
            cbar=True, annot_kws={'size': 14})
ax1.set_title(f'Confusion Matrix\nAccuracy: {val_acc:.1%}, F1-Score: {val_f1:.4f}', 
              fontweight='bold')
ax1.set_ylabel('True Label', fontweight='bold')
ax1.set_xlabel('Predicted Label', fontweight='bold')

# ROC Curve
from sklearn.metrics import roc_curve
ax2 = axes[0, 1]
fpr, tpr, _ = roc_curve(y_val, y_val_proba)
ax2.plot(fpr, tpr, linewidth=3, color='#4ECDC4', 
         label=f'Shallow NN (AUC = {val_auc:.3f})')
ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, label='Random')
ax2.set_xlabel('False Positive Rate', fontsize=11, fontweight='bold')
ax2.set_ylabel('True Positive Rate', fontsize=11, fontweight='bold')
ax2.set_title('ROC Curve', fontweight='bold')
ax2.legend(fontsize=10)
ax2.grid(True, alpha=0.3)

# Metrics Bar Chart
ax3 = axes[1, 0]
metrics_names = ['Accuracy', 'Balanced\nAccuracy', 'Precision', 'Recall', 'F1-Score', 'ROC-AUC']
metrics_values = [val_acc, val_bal_acc, val_prec, val_rec, val_f1, val_auc]
colors = ['#FF6B6B', '#4ECDC4', '#45B7D1', '#96CEB4', '#FFEAA7', '#DFE6E9']

bars = ax3.bar(metrics_names, metrics_values, color=colors, alpha=0.8, 
               edgecolor='black', linewidth=1.5)
ax3.set_ylabel('Score', fontsize=11, fontweight='bold')
ax3.set_title('Performance Metrics', fontweight='bold')
ax3.set_ylim(0, 1.0)
ax3.grid(True, alpha=0.3, axis='y')
ax3.axhline(y=0.5, color='red', linestyle='--', linewidth=1, alpha=0.5)

for bar, val in zip(bars, metrics_values):
    height = bar.get_height()
    ax3.text(bar.get_x() + bar.get_width()/2., height,
            f'{val:.3f}',
            ha='center', va='bottom', fontweight='bold', fontsize=9)

# Probability Distribution
ax4 = axes[1, 1]
ax4.hist([y_val_proba[y_val == 0], y_val_proba[y_val == 1]], 
         bins=20, label=['Unoccupied', 'Occupied'], 
         color=['#95E1D3', '#F38181'], alpha=0.7, edgecolor='black')
ax4.set_xlabel('Predicted Probability (Occupied)', fontsize=11, fontweight='bold')
ax4.set_ylabel('Frequency', fontsize=11, fontweight='bold')
ax4.set_title('Prediction Probability Distribution', fontweight='bold')
ax4.legend(fontsize=10)
ax4.grid(True, alpha=0.3, axis='y')
ax4.axvline(x=0.5, color='red', linestyle='--', linewidth=2)

plt.tight_layout()
plt.savefig('shallow_nn_results.png', dpi=300, bbox_inches='tight')
print("   Saved: shallow_nn_results.png")

# Save results
print("\n12. Saving outputs...")

results_df = pd.DataFrame({
    'true_label': y_val,
    'predicted_label': y_val_pred,
    'probability_occupied': y_val_proba,
    'correct': y_val == y_val_pred
})
results_df.to_csv('shallow_nn_predictions.csv', index=False)
print("   Saved: shallow_nn_predictions.csv")

with open('shallow_nn_model.pkl', 'wb') as f:
    pickle.dump(model, f)
print("   Saved: shallow_nn_model.pkl")

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)
print("   Saved: scaler.pkl")

# Summary report
summary = f"""
{'='*80}
SHALLOW NEURAL NETWORK - OCCUPANCY DETECTION
SUMMARY REPORT
{'='*80}

MODEL ARCHITECTURE:
  Input Layer:       {len(features)} features
  Hidden Layer:      50 neurons (ReLU activation)
  Output Layer:      2 classes (Softmax activation)
  Total Parameters:  {(len(features)*50 + 50*2 + 50 + 2):,}

TRAINING CONFIGURATION:
  Optimizer:         Adam
  Learning Rate:     0.01 (adaptive)
  Batch Size:        32
  Max Iterations:    300
  Actual Iterations: {model.n_iter_}
  Final Loss:        {model.loss_:.6f}
  Regularization:    L2 (alpha=0.01)

DATASET INFORMATION:
  Training Samples:   {len(y_train):,}
  Validation Samples: {len(y_val):,}
  Total Samples:      {len(y_train) + len(y_val):,}
  Features Used:      {', '.join(features)}

VALIDATION PERFORMANCE:
  Accuracy:           {val_acc:.4f} ({val_acc*100:.1f}%)
  Balanced Accuracy:  {val_bal_acc:.4f} ({val_bal_acc*100:.1f}%)
  Precision:          {val_prec:.4f}
  Recall:             {val_rec:.4f}
  F1-Score:           {val_f1:.4f}
  ROC-AUC:            {val_auc:.4f}

CONFUSION MATRIX:
                Predicted
            Unoccupied  Occupied
  Actual
  Unoccupied    {tn:3d}       {fp:3d}
  Occupied      {fn:3d}       {tp:3d}

INTERPRETATION:
  True Negatives:   {tn} - Correctly identified unoccupied
  False Positives:  {fp} - Incorrectly predicted occupied
  False Negatives:  {fn} - Missed occupied cases
  True Positives:   {tp} - Correctly identified occupied
  
  Specificity:      {specificity:.4f} ({specificity*100:.1f}%)
  Sensitivity:      {sensitivity:.4f} ({sensitivity*100:.1f}%)

{'='*80}
"""

with open('shallow_nn_report.txt', 'w') as f:
    f.write(summary)
print("   Saved: shallow_nn_report.txt")

print("\n" + "="*80)
print("SUMMARY")
print("="*80)
print(f"\nValidation Results:")
print(f"  Accuracy:          {val_acc*100:.1f}%")
print(f"  Balanced Accuracy: {val_bal_acc*100:.1f}%")
print(f"  F1-Score:          {val_f1:.4f}")
print(f"  Precision:         {val_prec:.4f}")
print(f"  Recall:            {val_rec:.4f}")

print(f"\nModel Architecture:")
print(f"  Input:  {len(features)} features")
print(f"  Hidden: 50 neurons (ReLU)")
print(f"  Output: 2 classes")

print(f"\nFiles Generated:")
print(f"  - shallow_nn_results.png")
print(f"  - shallow_nn_predictions.csv")
print(f"  - shallow_nn_model.pkl")
print(f"  - scaler.pkl")
print(f"  - shallow_nn_report.txt")

print("\n" + "="*80)
print("COMPLETE")
print("="*80)
