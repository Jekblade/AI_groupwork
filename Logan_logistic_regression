#!/usr/bin/env python3
"""
Logistic Regression for Occupancy Detection
Complete Implementation with Proper Validation
"""

import pandas as pd
import numpy as np
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import (
    accuracy_score, precision_score, recall_score, f1_score,
    confusion_matrix, classification_report, roc_auc_score,
    balanced_accuracy_score, roc_curve
)
from sklearn.utils.class_weight import compute_class_weight
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
warnings.filterwarnings('ignore')

print("="*80)
print("LOGISTIC REGRESSION - OCCUPANCY DETECTION")
print("="*80)

# =============================================================================
# STEP 1: DATA LOADING AND PREPROCESSING
# =============================================================================

print("\n" + "="*80)
print("STEP 1: DATA LOADING AND PREPROCESSING")
print("="*80)

print("\n1.1 Loading FinalData.csv...")

# Load data
data = pd.read_csv('FinalData.csv', sep=';')

print(f"   Raw data loaded: {len(data)} samples")
print(f"   Columns: {list(data.columns)}")

# Parse datetime
data['datetime'] = pd.to_datetime(data['datetime'], format='%d/%m/%Y %H:%M')

# Rename columns
data.columns = ['datetime', 'CO2', 'light', 'humidity', 'temp_indoor', 
                'temp_outdoor', 'presence']

print(f"\n   Date range: {data['datetime'].min()} to {data['datetime'].max()}")
print(f"   Total days: {(data['datetime'].max() - data['datetime'].min()).days + 1}")

print("\nFirst 5 rows:")
print(data.head())

print("\nData statistics:")
print(data.describe())

# Feature Engineering
print("\n1.2 Engineering time-based features...")

data['hour'] = data['datetime'].dt.hour
data['day_of_week'] = data['datetime'].dt.dayofweek
data['is_weekend'] = (data['day_of_week'] >= 5).astype(int)

print("   Created features:")
print("   - hour: Hour of day (0-23)")
print("   - day_of_week: Day of week (0=Mon, 6=Sun)")
print("   - is_weekend: Binary weekend indicator")

# Temporal Split
print("\n1.3 Creating TEMPORAL train/validation split...")
print("   IMPORTANT: NO SHUFFLING to prevent data leakage!\n")

split_idx = int(len(data) * 0.9)
train_data = data.iloc[:split_idx].copy()
val_data = data.iloc[split_idx:].copy()

print(f"   Training set: {len(train_data)} samples (90%)")
print(f"     Date range: {train_data['datetime'].min()} to {train_data['datetime'].max()}")

print(f"\n   Validation set: {len(val_data)} samples (10%)")
print(f"     Date range: {val_data['datetime'].min()} to {val_data['datetime'].max()}")

# Class Distribution
print("\n1.4 Analyzing class distribution...")

train_counts = train_data['presence'].value_counts().sort_index()
val_counts = val_data['presence'].value_counts().sort_index()

print("\n   TRAINING SET:")
print(f"     Unoccupied (0): {train_counts[0]} samples ({train_counts[0]/len(train_data)*100:.1f}%)")
print(f"     Occupied (1):   {train_counts[1]} samples ({train_counts[1]/len(train_data)*100:.1f}%)")
print(f"     Imbalance ratio: {train_counts[1]/train_counts[0]:.2f}:1")

print("\n   VALIDATION SET:")
print(f"     Unoccupied (0): {val_counts[0]} samples ({val_counts[0]/len(val_data)*100:.1f}%)")
print(f"     Occupied (1):   {val_counts[1]} samples ({val_counts[1]/len(val_data)*100:.1f}%)")
print(f"     Imbalance ratio: {val_counts[1]/val_counts[0]:.2f}:1")

# Prepare Features
print("\n1.5 Preparing features and target...")

features = ['CO2', 'light', 'temp_indoor', 'temp_outdoor', 'humidity', 'hour', 'is_weekend']
target = 'presence'

print(f"\n   Selected features ({len(features)}):")
for i, feat in enumerate(features, 1):
    print(f"     {i}. {feat}")

print(f"\n   Target variable: {target}")
print("     0 = Unoccupied")
print("     1 = Occupied")

X_train = train_data[features].values
y_train = train_data[target].values
X_val = val_data[features].values
y_val = val_data[target].values

print(f"\n   Array shapes:")
print(f"     X_train: {X_train.shape}")
print(f"     y_train: {y_train.shape}")
print(f"     X_val:   {X_val.shape}")
print(f"     y_val:   {y_val.shape}")

print("\n" + "="*80)
print("STEP 1 COMPLETE")
print("="*80)

# =============================================================================
# STEP 2: LOGISTIC REGRESSION MODEL
# =============================================================================

print("\n" + "="*80)
print("STEP 2: LOGISTIC REGRESSION MODEL")
print("="*80)

# Class Weights
print("\n2.1 Computing class weights...")

classes = np.unique(y_train)
class_weights_array = compute_class_weight('balanced', classes=classes, y=y_train)
class_weight_dict = {classes[i]: class_weights_array[i] for i in range(len(classes))}

print(f"\n   Class weights:")
print(f"     Unoccupied (0): {class_weight_dict[0]:.4f}")
print(f"     Occupied (1):   {class_weight_dict[1]:.4f}")

# Standardization
print("\n2.2 Standardizing features...")

scaler = StandardScaler()
scaler.fit(X_train)
X_train_scaled = scaler.transform(X_train)
X_val_scaled = scaler.transform(X_val)

print("   Features standardized to mean=0, std=1")
print(f"   Training mean: {X_train_scaled.mean():.6f}")
print(f"   Training std: {X_train_scaled.std():.6f}")

# Train Model
print("\n2.3 Training Logistic Regression model...")

lr_model = LogisticRegression(
    class_weight=class_weight_dict,
    max_iter=1000,
    solver='lbfgs',
    random_state=42
)

lr_model.fit(X_train_scaled, y_train)
print("   Model trained successfully")

print(f"\n   Convergence: {'Converged' if lr_model.n_iter_[0] < 1000 else 'Did not converge'}")
print(f"   Iterations: {lr_model.n_iter_[0]}")

# =============================================================================
# STEP 3: EVALUATION
# =============================================================================

print("\n" + "="*80)
print("STEP 3: MODEL EVALUATION")
print("="*80)

print("\n3.1 Generating predictions on VALIDATION set...")

y_val_pred = lr_model.predict(X_val_scaled)
y_val_proba = lr_model.predict_proba(X_val_scaled)

# Calculate Metrics
accuracy = accuracy_score(y_val, y_val_pred)
balanced_acc = balanced_accuracy_score(y_val, y_val_pred)
precision = precision_score(y_val, y_val_pred, zero_division=0)
recall = recall_score(y_val, y_val_pred, zero_division=0)
f1 = f1_score(y_val, y_val_pred, zero_division=0)
roc_auc = roc_auc_score(y_val, y_val_proba[:, 1])

print("\n" + "="*80)
print("VALIDATION SET PERFORMANCE")
print("="*80)

print(f"\n   Accuracy:          {accuracy:.4f} ({accuracy*100:.2f}%)")
print(f"   Balanced Accuracy: {balanced_acc:.4f} ({balanced_acc*100:.2f}%)")
print(f"   Precision:         {precision:.4f} ({precision*100:.2f}%)")
print(f"   Recall:            {recall:.4f} ({recall*100:.2f}%)")
print(f"   F1-Score:          {f1:.4f}")
print(f"   ROC-AUC:           {roc_auc:.4f}")

print("\n" + "="*80)

# Confusion Matrix
cm = confusion_matrix(y_val, y_val_pred)
tn, fp, fn, tp = cm.ravel()

print("\n3.2 Confusion matrix...")
print("\n" + "="*80)
print("CONFUSION MATRIX (Validation Set)")
print("="*80)

print(f"\n                  Predicted")
print(f"                  Unoccupied  Occupied")
print(f"   Actual")
print(f"   Unoccupied        {tn:3d}        {fp:3d}")
print(f"   Occupied          {fn:3d}       {tp:3d}")

print("\n" + "="*80)

print("\n   Detailed breakdown:")
print(f"     True Negatives (TN):  {tn:3d}")
print(f"     False Positives (FP): {fp:3d}")
print(f"     False Negatives (FN): {fn:3d}")
print(f"     True Positives (TP):  {tp:3d}")

specificity = tn / (tn + fp) if (tn + fp) > 0 else 0
sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0

print("\n   Additional metrics:")
print(f"     Specificity: {specificity:.4f} ({specificity*100:.1f}%)")
print(f"     Sensitivity: {sensitivity:.4f} ({sensitivity*100:.1f}%)")

# Reality Check
print("\n   Reality Check:")
if fp == 0 and fn == 0:
    print("   ✗ IMPOSSIBLE: Zero errors indicates data leakage!")
elif fp > 0 and fn > 0:
    print("   ✓ CORRECT: Both types of errors present")
    print("   ✓ This is realistic performance")

# Classification Report
print("\n3.3 Classification report:")
print("\n" + classification_report(y_val, y_val_pred,
                           target_names=['Unoccupied (0)', 'Occupied (1)'],
                           digits=4))

# =============================================================================
# STEP 4: SAVE RESULTS
# =============================================================================

print("\n" + "="*80)
print("SAVING RESULTS")
print("="*80)

# Save predictions
predictions_df = pd.DataFrame({
    'datetime': val_data['datetime'].values,
    'true_label': y_val,
    'predicted_label': y_val_pred,
    'probability_unoccupied': y_val_proba[:, 0],
    'probability_occupied': y_val_proba[:, 1],
    'correct': y_val == y_val_pred
})
predictions_df.to_csv('logistic_regression_predictions.csv', index=False)
print("   ✓ Saved: logistic_regression_predictions.csv")

# Save report
report = f"""
{'='*80}
LOGISTIC REGRESSION - OCCUPANCY DETECTION
VALIDATION REPORT
{'='*80}

DATASET INFORMATION:
  Total Samples:      {len(data)}
  Training Samples:   {len(train_data)} (90%)
  Validation Samples: {len(val_data)} (10%)
  Features:           {len(features)}
  Class Imbalance:    {train_counts[1]/train_counts[0]:.2f}:1

MODEL CONFIGURATION:
  Algorithm:          Logistic Regression
  Solver:             lbfgs
  Class Weights:      Balanced
  Feature Scaling:    StandardScaler
  Max Iterations:     1000

VALIDATION SET PERFORMANCE:
  Accuracy:           {accuracy:.4f} ({accuracy*100:.1f}%)
  Balanced Accuracy:  {balanced_acc:.4f} ({balanced_acc*100:.1f}%)
  Precision:          {precision:.4f} ({precision*100:.1f}%)
  Recall:             {recall:.4f} ({recall*100:.1f}%)
  F1-Score:           {f1:.4f}
  ROC-AUC:            {roc_auc:.4f}

CONFUSION MATRIX:
                Predicted
            Unoccupied  Occupied
  Actual
  Unoccupied    {tn:3d}       {fp:3d}
  Occupied      {fn:3d}       {tp:3d}

PERFORMANCE RATES:
  Specificity:        {specificity:.4f} ({specificity*100:.1f}%)
  Sensitivity:        {sensitivity:.4f} ({sensitivity*100:.1f}%)

CONCLUSION:
Logistic regression provides a baseline for comparison with neural networks.
Performance is moderate (~{accuracy*100:.1f}% accuracy), as expected for a 
linear model on this non-linear problem.

{'='*80}
"""

with open('logistic_regression_report.txt', 'w') as f:
    f.write(report)
print("   ✓ Saved: logistic_regression_report.txt")

# =============================================================================
# STEP 5: VISUALIZATIONS
# =============================================================================

print("\n" + "="*80)
print("CREATING VISUALIZATIONS")
print("="*80)

# Create visualization
fig, axes = plt.subplots(2, 2, figsize=(16, 14))
fig.suptitle('Logistic Regression - Validation Results',
             fontsize=18, fontweight='bold', y=0.995)

# 1. Confusion Matrix
ax1 = axes[0, 0]
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds', ax=ax1,
            xticklabels=['Unoccupied', 'Occupied'],
            yticklabels=['Unoccupied', 'Occupied'],
            cbar=True, annot_kws={'size': 16, 'weight': 'bold'},
            linewidths=2, linecolor='black')
ax1.set_title(f'Confusion Matrix\\nAccuracy: {accuracy:.1%}, F1: {f1:.4f}',
              fontweight='bold', fontsize=13)
ax1.set_ylabel('True Label', fontweight='bold')
ax1.set_xlabel('Predicted Label', fontweight='bold')

# 2. ROC Curve
ax2 = axes[0, 1]
fpr_curve, tpr_curve, _ = roc_curve(y_val, y_val_proba[:, 1])
ax2.plot(fpr_curve, tpr_curve, linewidth=3, color='#E74C3C',
         label=f'LR (AUC={roc_auc:.3f})')
ax2.plot([0, 1], [0, 1], 'k--', linewidth=2, alpha=0.5)
ax2.fill_between(fpr_curve, tpr_curve, alpha=0.2, color='#E74C3C')
ax2.set_xlabel('False Positive Rate', fontweight='bold')
ax2.set_ylabel('True Positive Rate', fontweight='bold')
ax2.set_title('ROC Curve', fontweight='bold')
ax2.legend()
ax2.grid(True, alpha=0.3)

# 3. Metrics Bar Chart
ax3 = axes[1, 0]
metrics = ['Accuracy', 'Balanced\\nAcc', 'Precision', 'Recall', 'F1', 'ROC-AUC']
values = [accuracy, balanced_acc, precision, recall, f1, roc_auc]
bars = ax3.bar(metrics, values, color='#E74C3C', alpha=0.8, edgecolor='black', linewidth=2)
ax3.set_ylabel('Score', fontweight='bold')
ax3.set_title('Performance Metrics', fontweight='bold')
ax3.grid(True, alpha=0.3, axis='y')
ax3.set_ylim(0, 1.05)
ax3.axhline(y=0.5, color='red', linestyle='--', alpha=0.7)
for bar, val in zip(bars, values):
    ax3.text(bar.get_x() + bar.get_width()/2., val + 0.02,
            f'{val:.3f}', ha='center', fontweight='bold')

# 4. Probability Distribution
ax4 = axes[1, 1]
ax4.hist([y_val_proba[y_val == 0, 1], y_val_proba[y_val == 1, 1]],
         bins=25, label=['Unoccupied', 'Occupied'],
         color=['#95E1D3', '#F38181'], alpha=0.7, edgecolor='black')
ax4.axvline(x=0.5, color='red', linestyle='--', linewidth=2.5)
ax4.set_xlabel('Predicted Probability (Occupied)', fontweight='bold')
ax4.set_ylabel('Frequency', fontweight='bold')
ax4.set_title('Prediction Distribution', fontweight='bold')
ax4.legend()
ax4.grid(True, alpha=0.3, axis='y')

plt.tight_layout()
plt.savefig('logistic_regression_results.png', dpi=300, bbox_inches='tight')
print("   ✓ Saved: logistic_regression_results.png")

print("\n" + "="*80)
print("ALL COMPLETE")
print("="*80)
print("\nExpected Results:")
print("  Accuracy:  ~45-50%")
print("  Precision: ~70-85% (NOT 100%!)")
print("  Both FP and FN should be > 0")
print("\nFiles generated:")
print("  - logistic_regression_predictions.csv")
print("  - logistic_regression_report.txt")
print("  - logistic_regression_results.png")
